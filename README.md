# Emotion-Aware Conversational AI for Mental Health Support

## ğŸ“‹ Project Overview

This project implements a **transformer-based emotion detection system** for mental health applications. The system uses the **GoEmotions dataset** (28 emotion categories) and fine-tunes **DistilBERT** for accurate emotion classification from text.

### ğŸ¯ System Capabilities

âœ… **Emotion Detection**: Classifies text into 28+ emotion categories  
âœ… **Multi-label Support**: Handles complex emotional states  
âœ… **High Accuracy**: Achieves strong F1 scores on validation data  
âœ… **Fast Inference**: Optimized for real-time predictions  
âœ… **Terminal Testing**: Interactive command-line interface  

---

## ğŸ“Š Dataset Information

**Dataset**: GoEmotions (Google Research)
- **Total Samples**: 211,742 Reddit comments
- **Emotion Labels**: 28 categories + neutral
- **Labels**: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral

---

## ğŸ—ï¸ System Architecture

### Phase 1: Data Preprocessing (`data_preprocessing.py`)
- Load and analyze GoEmotions dataset
- Text cleaning (URL removal, normalization)
- Convert multi-label to single-label
- Stratified train/val/test split (70/15/15)

### Phase 2: Model Training (`train_emotion_classifier.py`)
- **Base Model**: DistilBERT (distilbert-base-uncased)
- **Architecture**: Transformer encoder + classification head
- **Loss Function**: Cross-entropy loss
- **Optimizer**: AdamW with linear warmup
- **Training**: 3 epochs with validation monitoring

### Phase 3: Evaluation (`evaluate_model.py`)
- Compute accuracy, precision, recall, F1-score
- Generate confusion matrix visualization
- Per-class performance analysis
- Error analysis and misclassification patterns

### Phase 4: Inference (`inference.py`)
- Real-time emotion prediction
- Interactive terminal testing
- Batch prediction mode
- Confidence scores for top-K emotions

---

## ğŸš€ Installation & Setup

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (optional but recommended)
- 8GB+ RAM

### Step 1: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 2: Verify Installation

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"
```

---

## ğŸ“– Usage Guide

### **STEP 1: Data Preprocessing**

```bash
python data_preprocessing.py
```

**What it does**:
- Loads `go_emotions_dataset (1).csv`
- Analyzes dataset statistics
- Cleans and preprocesses text
- Creates train/val/test splits
- Saves processed data to `processed_data/`

**Output**:
```
processed_data/
â”œâ”€â”€ train.csv
â”œâ”€â”€ val.csv
â”œâ”€â”€ test.csv
â””â”€â”€ label_mapping.json
```

---

### **STEP 2: Model Training**

```bash
python train_emotion_classifier.py
```

**What it does**:
- Loads preprocessed data
- Initializes DistilBERT model
- Fine-tunes on emotion classification
- Monitors validation performance
- Saves best model checkpoint

**Training Configuration**:
- Model: DistilBERT-base-uncased
- Batch Size: 32
- Max Length: 128 tokens
- Epochs: 3
- Learning Rate: 2e-5
- Optimizer: AdamW

**Output**:
```
models/
â”œâ”€â”€ best_model/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â””â”€â”€ tokenizer files
â”œâ”€â”€ best_model_metrics.json
â””â”€â”€ test_results.json
```

**Expected Training Time**:
- CPU: ~4-6 hours
- GPU (CUDA): ~30-45 minutes

---

### **STEP 3: Model Evaluation**

```bash
python evaluate_model.py
```

**What it does**:
- Loads trained model
- Evaluates on test set
- Generates performance metrics
- Creates visualization plots
- Performs error analysis

**Output**:
```
models/
â”œâ”€â”€ confusion_matrix.png
â”œâ”€â”€ per_class_metrics.png
â”œâ”€â”€ error_analysis.txt
â”œâ”€â”€ evaluation_report.txt
â””â”€â”€ classification_report.txt
```

---

### **STEP 4: Interactive Testing**

```bash
python inference.py
```

**What it does**:
- Runs sample predictions
- Starts interactive terminal mode
- Allows real-time emotion detection

**Example Usage**:

```
Enter text: I am so happy and excited about this!

================================================================================
DETECTED EMOTIONS:
================================================================================
1. excitement       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 91.23%
2. joy              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  5.67%
3. optimism         â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  1.45%
================================================================================
```

---

## ğŸ“ˆ Model Architecture Details

### Why DistilBERT?

**Advantages**:
1. **Efficiency**: 40% smaller than BERT-base
2. **Speed**: 60% faster inference
3. **Performance**: Retains 97% of BERT's capabilities
4. **Memory**: Lower GPU memory requirements

### Model Components

```
Input Text
    â†“
Tokenization (WordPiece)
    â†“
DistilBERT Encoder (6 layers)
    - Self-attention mechanisms
    - Feed-forward networks
    - Layer normalization
    â†“
[CLS] Token Representation
    â†“
Classification Head (Linear + Softmax)
    â†“
Emotion Probabilities (28 classes)
```

### Hyperparameters

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| Max Length | 128 | Covers 95% of samples |
| Batch Size | 32 | Balance speed/memory |
| Learning Rate | 2e-5 | Standard for fine-tuning |
| Warmup Steps | 10% | Stable training start |
| Weight Decay | 0.01 | Regularization |
| Epochs | 3 | Prevent overfitting |

---

## ğŸ“Š Expected Performance

### Baseline Metrics

| Metric | Expected Range |
|--------|----------------|
| Accuracy | 65-75% |
| Weighted F1 | 63-73% |
| Precision | 64-74% |
| Recall | 65-75% |

**Note**: Performance varies by emotion category. Common emotions (joy, sadness, anger) typically achieve higher F1 scores (75-85%) than rare emotions (grief, remorse).

---

## ğŸ”§ Troubleshooting

### Issue: CUDA Out of Memory

**Solution**: Reduce batch size
```python
# In train_emotion_classifier.py
CONFIG = {
    'batch_size': 16,  # Reduce from 32
    ...
}
```

### Issue: Slow Training on CPU

**Solutions**:
1. Use smaller model: `distilbert-base-uncased` â†’ `distilroberta-base`
2. Reduce dataset size for prototyping
3. Use cloud GPU (Google Colab, Kaggle)

### Issue: Import Errors

**Solution**: Reinstall dependencies
```bash
pip install --upgrade torch transformers
```

---

## ğŸ“ Project Structure

```
bot 2/
â”œâ”€â”€ go_emotions_dataset (1).csv      # Original dataset
â”œâ”€â”€ data_preprocessing.py             # Data pipeline
â”œâ”€â”€ train_emotion_classifier.py       # Training script
â”œâ”€â”€ evaluate_model.py                 # Evaluation script
â”œâ”€â”€ inference.py                      # Testing script
â”œâ”€â”€ requirements.txt                  # Dependencies
â”œâ”€â”€ README.md                         # Documentation
â”œâ”€â”€ processed_data/                   # Generated
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ val.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ label_mapping.json
â””â”€â”€ models/                           # Generated
    â”œâ”€â”€ best_model/
    â”œâ”€â”€ confusion_matrix.png
    â”œâ”€â”€ per_class_metrics.png
    â”œâ”€â”€ error_analysis.txt
    â””â”€â”€ evaluation_report.txt
```

---

## ğŸ“ Methodology & Academic Context

### Problem Statement

Mental health applications require AI systems that can:
1. Detect emotional states from text
2. Generate appropriate empathetic responses
3. Maintain emotional context across conversations
4. Include safety mechanisms

This project addresses **Phase 1-3** of the problem statement:
- âœ… **Phase 1**: Problem analysis and architecture design
- âœ… **Phase 2**: Dataset analysis and preprocessing
- âœ… **Phase 3**: Emotion detection model training

### Why Transformers?

1. **Contextual Understanding**: Self-attention captures long-range dependencies
2. **Transfer Learning**: Pretrained on massive corpora
3. **State-of-the-Art**: Best performance on NLP benchmarks
4. **Flexibility**: Easy fine-tuning for specific tasks

### Training Strategy

**Fine-tuning Approach**:
- Start with pretrained DistilBERT weights
- Add classification head for 28 emotions
- Train only top layers initially (optional)
- Use emotion-specific loss function

**Evaluation Metrics**:
- **Accuracy**: Overall correctness
- **F1-Score**: Balance precision/recall (important for imbalanced classes)
- **Per-class Metrics**: Identify weak emotion categories
- **Confusion Matrix**: Understand error patterns

---

## ğŸ”¬ Future Enhancements (Phase 4-7)

### Phase 4: Response Generation
- Integrate DialoGPT/GPT-2 for empathetic responses
- Condition generation on detected emotions
- Implement emotion-aware prompting

### Phase 5: Conversation Memory
- LSTM/Transformer memory for context tracking
- Emotion history across turns
- Dynamic response adaptation

### Phase 6: Safety & Ethics
- Crisis keyword detection (self-harm, suicide)
- Ethical disclaimers
- Escalation to human professionals
- Bias analysis and mitigation

### Phase 7: User Study
- Human evaluation of empathy
- A/B testing response quality
- Mental health professional validation

---

## ğŸ“š References

1. **GoEmotions Dataset**: Demszky et al. (2020)
2. **DistilBERT**: Sanh et al. (2019)
3. **BERT**: Devlin et al. (2018)
4. **Mental Health NLP**: Calvo et al. (2017)

---

## âš ï¸ Ethical Considerations

**Important Disclaimers**:
1. This is a **research prototype**, not a clinical tool
2. **Not a replacement** for professional mental health care
3. Should include **crisis resource information**
4. Requires **informed consent** for user studies
5. Must comply with **HIPAA/GDPR** for real deployments

---

## ğŸ¤ Contributing

This is an educational research project. For improvements:
1. Test on additional emotion datasets
2. Experiment with larger models (BERT, RoBERTa)
3. Implement multi-label classification
4. Add response generation modules

---

## ğŸ“§ Support

For questions or issues:
1. Check error messages carefully
2. Review installation steps
3. Verify dataset integrity
4. Ensure sufficient system resources

---

## âœ… Quick Start Checklist

- [ ] Install Python 3.8+
- [ ] Install requirements: `pip install -r requirements.txt`
- [ ] Run preprocessing: `python data_preprocessing.py`
- [ ] Train model: `python train_emotion_classifier.py`
- [ ] Evaluate: `python evaluate_model.py`
- [ ] Test interactively: `python inference.py`

---

**Project Status**: Phase 1-3 Complete âœ…  
**Next Steps**: Implement emotion-conditioned response generation (Phase 4)

---

*Built for NLP research and mental health AI applications*
