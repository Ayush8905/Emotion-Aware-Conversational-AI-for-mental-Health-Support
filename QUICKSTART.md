# ðŸš€ QUICK START GUIDE

## âš¡ Get Started in 5 Minutes

### Prerequisites Check
```bash
# Check Python version (need 3.8+)
python --version

# Check if pip is installed
pip --version
```

---

## ðŸ“¦ Installation (2 minutes)

```bash
# Install all dependencies
pip install -r requirements.txt
```

**Expected output**: Installing packages... (takes 1-2 minutes)

---

## ðŸŽ¯ Training the Model (30-45 minutes on GPU, 4-6 hours on CPU)

### Option 1: Run Complete Pipeline (Recommended)
```bash
python run_pipeline.py
```

This will automatically:
1. âœ… Preprocess data
2. âœ… Train model  
3. âœ… Evaluate performance
4. âœ… Launch interactive testing

### Option 2: Run Steps Individually

**Step 1: Preprocess Data (~2 minutes)**
```bash
python data_preprocessing.py
```
Output: Creates `processed_data/` folder with train/val/test splits

**Step 2: Train Model (~30-45 min GPU, 4-6 hours CPU)**
```bash
python train_emotion_classifier.py
```
Output: Saves trained model to `models/best_model/`

**Step 3: Evaluate Model (~5 minutes)**
```bash
python evaluate_model.py
```
Output: Generates performance metrics and visualizations

**Step 4: Test Interactively**
```bash
python inference.py
```
Output: Interactive terminal for testing predictions

---

## ðŸ’¡ Quick Test Examples

Once training is complete, test with these examples:

```
Enter text: I'm so excited about this project!
â†’ excitement (89%), joy (7%), optimism (3%)

Enter text: This is really frustrating and annoying.
â†’ annoyance (76%), anger (18%), disappointment (4%)

Enter text: I feel sad and disappointed.
â†’ sadness (68%), disappointment (24%), grief (6%)

Enter text: Thank you so much for your help!
â†’ gratitude (91%), admiration (6%), approval (2%)
```

---

## ðŸ“Š What to Expect

### Training Progress
```
Epoch 1/3
================================================================================
Train Loss: 1.2456 | Train Acc: 0.6234
Val Loss:   0.9876 | Val Acc:   0.6789
Val F1:     0.6543

âœ“ New best model saved! (F1: 0.6543)
```

### Final Results
```
TEST SET RESULTS
================================================================================
Accuracy:  0.7012
Precision: 0.6945
Recall:    0.6983
F1 Score:  0.6867
```

---

## ðŸ” Verify Everything Works

### 1. Check files exist:
```bash
# After preprocessing
dir processed_data    # Windows
ls processed_data     # Linux/Mac

# After training
dir models\best_model       # Windows
ls models/best_model        # Linux/Mac
```

### 2. Quick sanity test:
```bash
python -c "from transformers import AutoTokenizer; print('âœ“ Transformers working!')"
python -c "import torch; print(f'âœ“ PyTorch {torch.__version__} working!')"
```

---

## âš ï¸ Troubleshooting

### Problem: "CUDA out of memory"
**Solution**: Edit `train_emotion_classifier.py`, line ~220:
```python
CONFIG = {
    'batch_size': 16,  # Change from 32 to 16 or 8
    ...
}
```

### Problem: "ModuleNotFoundError: No module named 'transformers'"
**Solution**: 
```bash
pip install transformers torch pandas scikit-learn
```

### Problem: Training is very slow
**Solutions**:
1. Use GPU (60x faster than CPU)
2. Reduce dataset for testing:
   - Edit `data_preprocessing.py`, add after loading data:
   ```python
   self.df = self.df.sample(n=10000)  # Use only 10k samples
   ```

### Problem: "FileNotFoundError: go_emotions_dataset (1).csv"
**Solution**: Ensure the CSV file is in the same folder as the scripts

---

## ðŸ“ˆ Expected Timeline

| Step | Time (GPU) | Time (CPU) |
|------|-----------|-----------|
| Install dependencies | 2 min | 2 min |
| Data preprocessing | 2 min | 3 min |
| Model training | 30-45 min | 4-6 hours |
| Evaluation | 3 min | 5 min |
| **TOTAL** | **~40 min** | **~5 hours** |

---

## âœ… Success Checklist

After running everything, you should have:

- [x] `processed_data/` folder with train/val/test CSV files
- [x] `models/best_model/` folder with trained model
- [x] `models/confusion_matrix.png` visualization
- [x] `models/per_class_metrics.png` visualization
- [x] `models/evaluation_report.txt` with metrics
- [x] Interactive inference working in terminal

---

## ðŸŽ“ Understanding the Output

### During Training:
- **Train Loss**: Should decrease (1.5 â†’ 0.8)
- **Val Accuracy**: Should increase (0.60 â†’ 0.70)
- **Val F1**: Should increase (0.58 â†’ 0.68)

### Final Metrics:
- **Accuracy > 65%**: âœ… Good performance
- **F1 Score > 63%**: âœ… Balanced precision/recall
- **Accuracy < 55%**: âš ï¸ May need hyperparameter tuning

---

## ðŸ“– Next Steps

1. **Review Results**: Check `models/evaluation_report.txt`
2. **Analyze Errors**: Read `models/error_analysis.txt`
3. **Test Thoroughly**: Use `inference.py` with diverse examples
4. **Experiment**: Try different models (roberta-base, bert-base)

---

## ðŸ’¬ Interactive Testing Examples

```bash
$ python inference.py

QUICK TEST - SAMPLE PREDICTIONS
================================================================================
INPUT TEXT: "I am so excited about this!"
DETECTED EMOTIONS:
1. excitement       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 91.23%
2. joy              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  5.67%
3. optimism         â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  1.45%
```

---

## ðŸ› ï¸ File Structure After Training

```
bot 2/
â”œâ”€â”€ go_emotions_dataset (1).csv
â”œâ”€â”€ data_preprocessing.py
â”œâ”€â”€ train_emotion_classifier.py
â”œâ”€â”€ evaluate_model.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ run_pipeline.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ TECHNICAL_DOCS.md
â”œâ”€â”€ QUICKSTART.md
â”‚
â”œâ”€â”€ processed_data/          â† Created after Step 1
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ val.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ label_mapping.json
â”‚
â””â”€â”€ models/                  â† Created after Step 2
    â”œâ”€â”€ best_model/
    â”‚   â”œâ”€â”€ config.json
    â”‚   â”œâ”€â”€ pytorch_model.bin
    â”‚   â””â”€â”€ tokenizer files
    â”œâ”€â”€ best_model_metrics.json
    â”œâ”€â”€ test_results.json
    â”œâ”€â”€ confusion_matrix.png
    â”œâ”€â”€ per_class_metrics.png
    â”œâ”€â”€ error_analysis.txt
    â”œâ”€â”€ evaluation_report.txt
    â””â”€â”€ classification_report.txt
```

---

## ðŸ”¥ Pro Tips

1. **Use GPU**: Training is 60x faster on GPU
2. **Monitor Progress**: Watch validation F1 score
3. **Early Stopping**: If val loss increases, training stops
4. **Best Model**: Always saved based on highest val F1
5. **Test Diverse Examples**: Try sarcasm, mixed emotions

---

## ðŸ“ž Need Help?

1. Check `TECHNICAL_DOCS.md` for detailed explanations
2. Review error messages carefully
3. Ensure all dependencies are installed
4. Verify dataset file exists and is readable

---

**Ready to start?** Run:
```bash
python run_pipeline.py
```

Good luck! ðŸŽ‰
